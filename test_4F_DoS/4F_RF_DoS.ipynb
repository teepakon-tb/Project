{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# โหลดข้อมูลจากไฟล์ CSV\n",
    "df = pd.read_csv('UNSW_NB15_testing-set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter 'attack_cat' column for 'Dos' and 'Normal' values\n",
    "filtered_df = df[df['attack_cat'].isin(['DoS', 'Normal'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ITD\\AppData\\Local\\Temp\\ipykernel_14460\\1130273881.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['attack_cat_encoded'] = filtered_df['attack_cat'].map(attack_cat_mapping)\n"
     ]
    }
   ],
   "source": [
    "attack_cat_mapping = {'DoS': 1, 'Normal': 0}\n",
    "filtered_df['attack_cat_encoded'] = filtered_df['attack_cat'].map(attack_cat_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  attack_cat  attack_cat_encoded\n",
      "0     Normal                   0\n",
      "1     Normal                   0\n",
      "2     Normal                   0\n",
      "3     Normal                   0\n",
      "4     Normal                   0\n"
     ]
    }
   ],
   "source": [
    "print(filtered_df[['attack_cat', 'attack_cat_encoded']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['spkts', 'dpkts', 'sbytes', 'dbytes']]\n",
    "y = filtered_df.loc[:, 'attack_cat_encoded']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# รวม X และ y เข้าด้วยกัน\n",
    "combined_data = pd.concat([X, y], axis=1)\n",
    "\n",
    "# หาจำนวนตัวอย่างที่น้อยที่สุด\n",
    "min_samples = combined_data['attack_cat_encoded'].value_counts().min()\n",
    "\n",
    "# สร้างข้อมูลที่ undersampled จากแต่ละกลุ่ม\n",
    "undersampled_data = combined_data.groupby('attack_cat_encoded').apply(lambda x: resample(x, n_samples=min_samples, random_state=42))\n",
    "\n",
    "# แยก X และ y ออกจาก undersampled_data\n",
    "X_resampled = undersampled_data[['spkts', 'dpkts', 'sbytes', 'dbytes']]\n",
    "y_resampled = undersampled_data['attack_cat_encoded']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Gain for spkts: 0.22455782178361727\n",
      "Information Gain for dpkts: 0.33317502573550173\n",
      "Information Gain for sbytes: 0.5674470766921671\n",
      "Information Gain for dbytes: 0.42600398494978897\n",
      "Seed = 1, Accuracy: 0.9828781084386465\n",
      "Confusion Matrix:\n",
      "[[2439   43]\n",
      " [  41 2383]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.98      0.98      2482\n",
      "         1.0       0.98      0.98      0.98      2424\n",
      "\n",
      "    accuracy                           0.98      4906\n",
      "   macro avg       0.98      0.98      0.98      4906\n",
      "weighted avg       0.98      0.98      0.98      4906\n",
      "\n",
      "Seed = 20, Accuracy: 0.9790052996331023\n",
      "Confusion Matrix:\n",
      "[[2406   57]\n",
      " [  46 2397]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.98      0.98      2463\n",
      "         1.0       0.98      0.98      0.98      2443\n",
      "\n",
      "    accuracy                           0.98      4906\n",
      "   macro avg       0.98      0.98      0.98      4906\n",
      "weighted avg       0.98      0.98      0.98      4906\n",
      "\n",
      "Seed = 100, Accuracy: 0.9834896045658378\n",
      "Confusion Matrix:\n",
      "[[2439   40]\n",
      " [  41 2386]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.98      0.98      2479\n",
      "         1.0       0.98      0.98      0.98      2427\n",
      "\n",
      "    accuracy                           0.98      4906\n",
      "   macro avg       0.98      0.98      0.98      4906\n",
      "weighted avg       0.98      0.98      0.98      4906\n",
      "\n",
      "Seed = 200, Accuracy: 0.9783938035059111\n",
      "Confusion Matrix:\n",
      "[[2421   41]\n",
      " [  65 2379]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.98      2462\n",
      "         1.0       0.98      0.97      0.98      2444\n",
      "\n",
      "    accuracy                           0.98      4906\n",
      "   macro avg       0.98      0.98      0.98      4906\n",
      "weighted avg       0.98      0.98      0.98      4906\n",
      "\n",
      "Seed = 1000, Accuracy: 0.9812474520994701\n",
      "Confusion Matrix:\n",
      "[[2380   41]\n",
      " [  51 2434]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.98      0.98      2421\n",
      "         1.0       0.98      0.98      0.98      2485\n",
      "\n",
      "    accuracy                           0.98      4906\n",
      "   macro avg       0.98      0.98      0.98      4906\n",
      "weighted avg       0.98      0.98      0.98      4906\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# หา Information Gain ของแต่ละ feature\n",
    "ig_scores = mutual_info_classif(X_resampled, y_resampled, discrete_features=False)\n",
    "\n",
    "# แสดง Information Gain ของแต่ละ feature\n",
    "for feature, ig_score in zip(X_resampled.columns, ig_scores):\n",
    "    print(f'Information Gain for {feature}: {ig_score}')\n",
    "\n",
    "# ใช้ DecisionTreeClassifier\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# วนซ้ำโดยใช้ค่า random seed แต่ละครั้ง\n",
    "for seed in [1, 20, 100, 200, 1000]:\n",
    "    # แบ่งข้อมูลเป็นชุดฝึกและชุดทดสอบ\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=seed)\n",
    "\n",
    "    # ใช้ DecisionTreeClassifier\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # ทำนายค่า 'label' ด้วยชุดทดสอบ\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # ประเมินประสิทธิภาพ\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    print(f'Seed = {seed}, Accuracy: {accuracy}')\n",
    "\n",
    "    # แสดง Confusion Matrix\n",
    "    conf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "\n",
    "    # แสดง Classification Report\n",
    "    class_report = metrics.classification_report(y_test, y_pred)\n",
    "    print('Classification Report:')\n",
    "    print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
